{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is capital of Austrailia'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict, List\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import  PromptTemplate, ChatPromptTemplate\n",
    "from langchain.prompts.few_shot import  FewShotChatMessagePromptTemplate, FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1,\n",
    "                   streaming=True, \n",
    "                   callbacks=[\n",
    "                      StreamingStdOutCallbackHandler(),\n",
    "                    ],\n",
    "                  )\n",
    "\n",
    "a_template = PromptTemplate.from_template(\"What is capital of {country}\")\n",
    "b_template = PromptTemplate(\n",
    "  template=\"What is capital of {country}\",\n",
    "  input_variables=[\"country\"],\n",
    ")\n",
    "a_template.format(country=\"Austria\")\n",
    "b_template.format(country=\"Austrailia\")\n",
    "# result = t | chat\n",
    "# result.invoke({\"country\":\"Austria\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:\n",
      "        I know this:\n",
      "        Capital: Ankara\n",
      "        Language: Turkish\n",
      "        Food: Kebabs and Baklava\n",
      "        Currency: Turkish Lira"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI:\\n        I know this:\\n        Capital: Ankara\\n        Language: Turkish\\n        Food: Kebabs and Baklava\\n        Currency: Turkish Lira')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "  \"Human:{question} \\n AI:{answer}\"\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "  example_prompt=example_prompt,\n",
    "  examples=examples,\n",
    "  input_variables=[\"country\",],\n",
    "  suffix=\"Human:What do you know about {country}?\"\n",
    ")\n",
    "\n",
    "# prompt.format(country=\"Turkey\")\n",
    "chain = prompt |chat\n",
    "chain.invoke({\n",
    "  \"country\":\"Turkey\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "example_prompt_chat = ChatPromptTemplate.from_messages([\n",
    "  (\"human\", \"What do you know about {question}?\"),\n",
    "  (\"ai\", \"{answer}\")\n",
    "])\n",
    "\n",
    "prompt_chat = FewShotChatMessagePromptTemplate(\n",
    "  example_prompt=example_prompt_chat,\n",
    "  examples=examples, \n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "  (\"system\",\"You are a geography expert\"),\n",
    "  prompt_chat,\n",
    "  (\"human\", \"What do you know about {country}?\"),\n",
    "])\n",
    "\n",
    "chain = final_prompt |chat\n",
    "chain.invoke({\"country\":\"Israel\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human:What do you know about Italy? \\n AI:\\n        I know this:\\n        Capital: Rome\\n        Language: Italian\\n        Food: Pizza and Pasta\\n        Currency: Euro\\n        \\n\\nHuman:What do you know about Brazil?'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "  def __init__(self, examples):\n",
    "    self.examples = examples\n",
    "\n",
    "  def add_example(self, example):\n",
    "    self.examples.append(example)\n",
    "\n",
    "  def select_examples(self, input_variables) :\n",
    "    from random import choice\n",
    "    return [choice(self.examples)]\n",
    "  \n",
    "  \n",
    "example_prompt = PromptTemplate.from_template(\n",
    "  \"Human:{question} \\n AI:{answer}\"\n",
    ")\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "  examples=examples,\n",
    "  example_prompt=example_prompt,\n",
    "  max_length=380,\n",
    ")\n",
    "\n",
    "# 내가 만든거\n",
    "example_selector_my = RandomExampleSelector(  \n",
    "  examples = examples,\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "  example_prompt=example_prompt,\n",
    "  example_selector=example_selector_my,\n",
    "\n",
    "  input_variables=[\"country\",],\n",
    "  suffix=\"Human:What do you know about {country}?\"\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Germany'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict, List\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import  PromptTemplate, ChatPromptTemplate\n",
    "from langchain.prompts.few_shot import  FewShotChatMessagePromptTemplate, FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "prompt=load_prompt(\"./prompt.yaml\")\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1,\n",
    "                   streaming=True, \n",
    "                   callbacks=[\n",
    "                      StreamingStdOutCallbackHandler(),\n",
    "                    ],\n",
    "                  )\n",
    "prompt.format(country=\"Germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrg! Me favorite food be rum and fish, matey! Aye, nothing beats a good ol' feast of fresh fish and a barrel of rum to wash it down with! Arg Arg!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"Arrrg! Me favorite food be rum and fish, matey! Aye, nothing beats a good ol' feast of fresh fish and a barrel of rum to wash it down with! Arg Arg!\")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "intro= PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example= PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start= PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final= PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "\n",
    "    {example}\n",
    "\n",
    "    {start}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompts= [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(final_prompt=final, pipeline_prompts=prompts,)\n",
    "# full_prompt.format(\n",
    "#   character =\"Pirate\",\n",
    "#   example_question=\"What is your location?\",\n",
    "#   example_answer=\"Arrrg! That is a secret!!  Arg Arg!!\",\n",
    "#   question=\"What is your food?\",\n",
    "# )\n",
    "\n",
    "chain = full_prompt | chat\n",
    "chain.invoke({\n",
    "    \"character\": \"Pirate\",\n",
    "    \"example_question\":\"What is your location?\",\n",
    "    \"example_answer\":\"Arrrg! That is a secret!!  Arg Arg!!\",\n",
    "    \"question\":\"What is your food?\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make italian pasta?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [1ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere is a basic recipe for making Italian pasta:\\n\\n1. On a clean work surface, pour the flour and make a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it is smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\\n6. After resting, roll out the dough using a pasta machine or a rolling pin until it is thin.\\n7. Cut the dough into desired shapes, such as fettuccine or spaghetti.\\n8. Cook the pasta in a large pot of boiling salted water for 2-3 minutes, or until al dente.\\n9. Drain the pasta and toss with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere is a basic recipe for making Italian pasta:\\n\\n1. On a clean work surface, pour the flour and make a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it is smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\\n6. After resting, roll out the dough using a pasta machine or a rolling pin until it is thin.\\n7. Cut the dough into desired shapes, such as fettuccine or spaghetti.\\n8. Cook the pasta in a large pot of boiling salted water for 2-3 minutes, or until al dente.\\n9. Drain the pasta and toss with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n\\nHere is a basic recipe for making Italian pasta:\\n\\n1. On a clean work surface, pour the flour and make a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it is smooth and elastic.\\n5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\\n6. After resting, roll out the dough using a pasta machine or a rolling pin until it is thin.\\n7. Cut the dough into desired shapes, such as fettuccine or spaghetti.\\n8. Cook the pasta in a large pot of boiling salted water for 2-3 minutes, or until al dente.\\n9. Drain the pasta and toss with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.globals import set_llm_cache, set_debug\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "\n",
    "#모든 response가 메모리에 저장된다.\n",
    "\n",
    "# set_llm_cache(InMemoryCache()) \n",
    "# set_llm_cache(SQLiteCache(\"cache.db\")) \n",
    "set_debug(True)\n",
    "\n",
    "chat=ChatOpenAI(\n",
    "  temperature=0.1,\n",
    "\n",
    ")\n",
    "chat.predict(\"How do you make italian pasta?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.predict(\"How do you make italian pasta?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is the recipe for soju\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [1ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Ingredients:\\n- 1 cup of rice\\n- 1 cup of water\\n- 1 tablespoon of nuruk (fermentation starter)\\n- 1 tablespoon of yeast\\n\\nInstructions:\\n1. Rinse the rice under cold water until the water runs clear.\\n2. In a large pot, combine the rice and water and bring to a boil. Reduce heat to low and simmer for 20 minutes, or until the rice is cooked.\\n3. Remove the pot from heat and let it cool to room temperature.\\n4. In a separate bowl, mix the nuruk and yeast with a little bit of warm water to form a paste.\\n5. Add the paste to the cooled rice and mix well.\\n6. Cover the pot with a clean cloth and let it ferment in a warm, dark place for 3-4 days.\\n7. After fermentation, strain the mixture through a cheesecloth to remove any solids.\\n8. Transfer the liquid to a clean bottle and store in the refrigerator.\\n9. Serve chilled and enjoy your homemade soju!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Ingredients:\\n- 1 cup of rice\\n- 1 cup of water\\n- 1 tablespoon of nuruk (fermentation starter)\\n- 1 tablespoon of yeast\\n\\nInstructions:\\n1. Rinse the rice under cold water until the water runs clear.\\n2. In a large pot, combine the rice and water and bring to a boil. Reduce heat to low and simmer for 20 minutes, or until the rice is cooked.\\n3. Remove the pot from heat and let it cool to room temperature.\\n4. In a separate bowl, mix the nuruk and yeast with a little bit of warm water to form a paste.\\n5. Add the paste to the cooled rice and mix well.\\n6. Cover the pot with a clean cloth and let it ferment in a warm, dark place for 3-4 days.\\n7. After fermentation, strain the mixture through a cheesecloth to remove any solids.\\n8. Transfer the liquid to a clean bottle and store in the refrigerator.\\n9. Serve chilled and enjoy your homemade soju!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is the recipe for Croissant bread\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [1ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Ingredients:\\n- 2 1/4 tsp active dry yeast\\n- 1/4 cup warm water\\n- 3 1/2 cups all-purpose flour\\n- 1/4 cup sugar\\n- 1 tsp salt\\n- 1 cup cold unsalted butter, cut into small pieces\\n- 1 cup cold milk\\n- 1 egg, beaten (for egg wash)\\n\\nInstructions:\\n1. In a small bowl, dissolve the yeast in warm water and let it sit for 5 minutes until foamy.\\n2. In a large mixing bowl, combine the flour, sugar, and salt. Cut in the cold butter using a pastry cutter or your fingers until the mixture resembles coarse crumbs.\\n3. Add the yeast mixture and milk to the flour mixture and mix until a dough forms.\\n4. Turn the dough out onto a floured surface and knead for about 5 minutes until smooth and elastic.\\n5. Shape the dough into a ball, cover with plastic wrap, and refrigerate for at least 1 hour.\\n6. Roll out the dough into a rectangle about 1/4 inch thick. Fold the dough into thirds like a letter, then roll it out again and fold into thirds. Repeat this process 2 more times.\\n7. Roll out the dough into a large rectangle about 1/4 inch thick. Cut the dough into triangles and roll each triangle into a croissant shape.\\n8. Place the croissants on a baking sheet lined with parchment paper, cover with a clean kitchen towel, and let rise in a warm place for 1-2 hours.\\n9. Preheat the oven to 375°F (190°C). Brush the croissants with the beaten egg wash.\\n10. Bake the croissants for 15-20 minutes until golden brown and flaky. Serve warm and enjoy!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Ingredients:\\n- 2 1/4 tsp active dry yeast\\n- 1/4 cup warm water\\n- 3 1/2 cups all-purpose flour\\n- 1/4 cup sugar\\n- 1 tsp salt\\n- 1 cup cold unsalted butter, cut into small pieces\\n- 1 cup cold milk\\n- 1 egg, beaten (for egg wash)\\n\\nInstructions:\\n1. In a small bowl, dissolve the yeast in warm water and let it sit for 5 minutes until foamy.\\n2. In a large mixing bowl, combine the flour, sugar, and salt. Cut in the cold butter using a pastry cutter or your fingers until the mixture resembles coarse crumbs.\\n3. Add the yeast mixture and milk to the flour mixture and mix until a dough forms.\\n4. Turn the dough out onto a floured surface and knead for about 5 minutes until smooth and elastic.\\n5. Shape the dough into a ball, cover with plastic wrap, and refrigerate for at least 1 hour.\\n6. Roll out the dough into a rectangle about 1/4 inch thick. Fold the dough into thirds like a letter, then roll it out again and fold into thirds. Repeat this process 2 more times.\\n7. Roll out the dough into a large rectangle about 1/4 inch thick. Cut the dough into triangles and roll each triangle into a croissant shape.\\n8. Place the croissants on a baking sheet lined with parchment paper, cover with a clean kitchen towel, and let rise in a warm place for 1-2 hours.\\n9. Preheat the oven to 375°F (190°C). Brush the croissants with the beaten egg wash.\\n10. Bake the croissants for 15-20 minutes until golden brown and flaky. Serve warm and enjoy!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "Tokens Used: 0\n",
      "\tPrompt Tokens: 0\n",
      "\tCompletion Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "\n",
    "chat=ChatOpenAI(\n",
    "  temperature=0.1, \n",
    ")\n",
    "\n",
    "with get_openai_callback() as usage:\n",
    "\n",
    "  a=chat.predict(\"What is the recipe for soju\")\n",
    "  b=chat.predict(\"What is the recipe for Croissant bread\")\n",
    "  print(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.openai import OpenAI\n",
    "chat=OpenAI(temperature=0.1, max_tokens=450, model=\"gpt-3.5-turbo-16k\")\n",
    "chat.save(\"model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moonk/Documents/coder/Python/fullstack-gpt/env/lib/python3.11/site-packages/langchain/llms/openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/moonk/Documents/coder/Python/fullstack-gpt/env/lib/python3.11/site-packages/langchain/llms/openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenAIChat(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo-16k', model_kwargs={'temperature': 0.1, 'max_tokens': 450, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms.loading import load_llm\n",
    "\n",
    "load_llm(\"model.json\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
